<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>数据结构与算法——查找</title>
      <link href="/2020/07/15/shu-ju-jie-gou-yu-suan-fa-cha-zhao/"/>
      <url>/2020/07/15/shu-ju-jie-gou-yu-suan-fa-cha-zhao/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1>查找</h1><hr><blockquote><p>查找是算法当中最为基本的一类算法。计算机运算的本质就是对于数据的操作，不论从宏观还是微观来看，计算机所做的事情都是，数据输入-数据处理-数据输出。但是由于计算机运算器的结构决定了，我们不能把所有数据都存储在运算器中，取而代之的是，我们把输入进来待处理的数据存放到一些存储介质中（可能是硬盘或是内存），在计算机处理器处理完之前处理的数据后，再将这部分数据找到，加载到运算器中进行处理。<br>由于计算机存储介质中存放了众多的数据，如何为运算器找到运算从众多的数据中所需的数据就是一个需要解决的问题。而查找就是找到所需数据的一种运算。</p></blockquote><blockquote><p>本章介绍了几种常见且基础的查找算法，通过这些算法的学习，读者可以对计算机如何找到所需数据又一个直观、深刻的认识。这将对以后的学习奠定一些基础。</p></blockquote><h3 id="二分查找">二分查找</h3><h4 id="何为二分查找">何为二分查找</h4><h5 id="问题">问题</h5><blockquote><p>假如有一串排好序的数字，然后让你去找数字8在哪个位置，你该怎么找？</p></blockquote><p>你可能会说，这还需要找吗，一眼不就看出来了？<br>是的没错，确实这个问题简单的可以通过肉眼观察一眼的到结果。但是，计算机可没有这种“一眼看出”的能力。</p><p>那么计算机怎么做呢？有人可能会想，最简单的做法，不就是让计算机一个一个的去比较嘛，从左到右，一个一个比较，直到找到符合条件的那个。</p><p>确实，可以这么做，我们的计算机如今的算力对于这点小问题简直不在话下。但是，如果这个排序的数字序列极其大呢，试想如果有一个亿的数字，你愿意去一个一个比较嘛？</p><p>于是我们就想怎么样能够快速的用很少次数的比较，来快速找到元素是否在这个序列中，并返回它所在的位置。</p><p>就像是做数学题一样，我们发现，我们居然有个条件没有用啊——“有序的”数字序列。这个有序的，其实是一个很有用的条件。因为原序列是有序的，我们可以用我们要找的那个元素和这个序列中间的数字进行比较，如果我们的数字小于序列中位数，那么我们要找的数字如果存在，那么必定是在序列的左半部分；（反之，如果我们的数字大于中间数，则需要去序列右边）。然后用去除一半的那部分序列继续进行之前的比较操作，直到找到我们要找的元素，或者序列被切除到只剩一个元素却也不是我们要找的元素（查找元素不存在于原序列中）。</p><p>我们可以通过一个简单的例子来演示一下：</p><p>又一个有序数组：「1，5，7，8，12，25，31，33，55，65」<br>我们要查找数字55是否在这组数字中。</p><p>于是就有：</p><pre><code>第一步：目标数字55与数组中间数比较：55&gt;25,则取右半部分为新的数组；第二步：目标数字55与新的数组中间数比较：「25，31，33，55，65」中位数为33，55&gt;33，则再取右半部分；第三步：目标数字55与新数组中间数比较：「33，55，65」，55=55，找到了！注：如果查找的是54，那么步骤与上面相同，只不过，第三步比较，得出数据不存在的结论。</code></pre><h5 id="定义">定义</h5><p>二分查找，是一种基于贪心算法（参照后续章节：进阶算法设计与分析）的查找算法。他可以将查找问题进行优化，减少比较次数，降低问题运算规模，提高查找效率，节省运算时间。</p><h4 id="二分查找的递归实现">二分查找的递归实现</h4><pre><code> python# 返回 x 在 arr 中的索引，如果不存在返回 -1def binarySearch (arr, l, r, x): # 基本判断if r &gt;= l: mid = int(l + (r - l)/2)# 元素整好的中间位置if arr[mid] == x: return mid # 元素小于中间位置的元素，只需要再比较左边的元素elif arr[mid] &gt; x: return binarySearch(arr, l, mid-1, x) # 元素大于中间位置的元素，只需要再比较右边的元素else: return binarySearch(arr, mid+1, r, x) else: # 不存在return -1# 测试数组arr = [ 2, 3, 4, 10, 40 ] x = 10# 函数调用result = binarySearch(arr, 0, len(arr)-1, x) if result != -1: print (&quot;元素在数组中的索引为 %d&quot; % result )else: print (&quot;元素不在数组中&quot;)</code></pre><h4 id="二分查找的时间复杂度分析">二分查找的时间复杂度分析</h4><p>根据前面所学的算法的时间复杂度分析，我们在这里来看看如何分析二分查找的渐进时间复杂度。并与顺序比较的方式的复杂度做以比较。</p><p>顺序查找的时间复杂度很明显就是：O(n),<br>而二分查找的时间复杂度我们讨论如下：<br>* 最优情形：一次就找到（要查找元素恰好在中间位置）——O(1)<br>* 最坏情形：一直到最后都没找到——O(log2 n)</p><blockquote><p>最坏情形推导过程：<br>最坏情形也就是，n个元素的序列被二分到最后只剩一个元素，我们设一共分了m次。那么2^m = n, 于是m = log2 n。 我们发现这个m就是我们要求的最坏情形下的次数。</p></blockquote><p>经过我们上面的推导，我们可以看出，二分查找渐进时间复杂度与顺序查找相比确实提升了查找效率，减少了比较次数。</p><h4 id="二分查找使用的条件">二分查找使用的条件</h4><p>我们上面比较了二分查找与顺序查找的时间复杂度，二分查找看起来比起基本的顺序查找好很多啊，那以后涉及到查找就用它了？<br>答案是不行，二分查找是有它特有的条件的，只有在条件满足的情况下，才能使用。<br>二分查找适用于，关键字有序的采用顺序存储的线性表。</p><p>关键字（就是要查找的数据）有序，是使用二分查找的必要条件，只有有序的序列才能进行“二分”。</p><p>需要采取顺序存储是因为，顺序表在存储器中的存储是连续的，进行二分操作的效率高。试想如果是链表存储的线性表，对其进行二分查找，光是找到中间位置就耗费了很大功夫。（链表和顺序表不同，数据在存储器中离散存储，而且通过指针访问，不具有顺序表随机访问的特性）</p><p>好了，明确了二分查找的使用条件，你可能有点沮丧，这适用范围也太小了吧，没关系，我们还有很多查找算法，接下来我们看看，另一个经典查找算法——散列查找。</p><h3 id="散列查找">散列查找</h3><p>我们前面学过了散列表，它是通过散列（哈希）函数来实现对数据进行映射存储的。对数据进行存储时，数据关键字在经过散列函数的运算后，被映射到另一个域，这个新的域就是关键字存放的位置。散列的目的就是通过这样的过程达到的（通过预设的分类方法，将一堆预处理的数据进行分类存储，并且尽量保证这种分类方法使得存放数据的位置尽可能的分散）。</p><h4 id="什么是散列查找">什么是散列查找</h4><p>明确了散列表的存储过程，那么其实理解散列查找就很容易了。散列查找其实就是散列存储的逆过程。<br>即：通过散列函数对所查询关键字进行计算，然后查找对应关键字的过程。</p><h5 id="问题-或者-现实例子">问题 或者 现实例子</h5><p>同样我们举一个例子来让大家理解散列查找。<br>假设我们有一个散列函数：散列值 = 关键字x2-1<br>散列表中现在存储的关键字为：[3，5，7，11，21，31]<br>现在我们要分别查找关键字 4和7是否在该散列表中。</p><p>解答过程：<br>通过散列函数对所查找关键字求散列值：<br>关键字4对应的散列值= 4 x 2 - 1 =7<br>关键字7对应的散列值= 7 x 2 - 1 = 13<br>于是我们可以了解到关键字为4数据存在于散列表中，<br>而关键字7所对应的数据没有存储在散列表中。</p><h4 id="散列查找的类型">散列查找的类型</h4><p>以上的例子是为了大家理解方便而举的一个不是很严谨的例子。<br>实际上，散列函数需要满足一定的条件，以使得散列的效果最佳。</p><h5 id="散列函数">散列函数</h5><p>一个好的散列函数应当尽可能的满足简单均匀散列假设：每个关键字都被等可能地散列到m个槽位的任意一个，并且与其他关键字已散列到哪个槽位无关。</p><p>接下来我们就来讲讲现有的一些比较好的散列函数。</p><h5 id="除法散列法">除法散列法</h5><p>除法散列法，在很多教材中被称作除余法，简言之，就是将数字关键字除以一个特定的数字，得到的余数就作为它的散列值。这个特定的数字m一般是散列表的容量大小，这么做的原因是，由它当除数，那么余数只可能是在0到m之间的整数，这些整数恰好可以标示散列前的关键字，将其放置到m个位置中对应的散列位置。<br>散列函数可以描述为：h(x) = k mod m , 其中mod就是取余的意思。</p><p>当然，并不是任何数字都合适做m，2的幂就不合适，为什么呢？<br>答：我们知道，数据在计算机内的存储和表示都是二进制，那么，如果我们选取2的幂次做除数，余数其实就是，原关键字转化为二进制后的后面几位。</p><p>例如，我们用2的3次方作为m（m=8），对于关键字7，23来说，它们的二进制分别表示为00111，10111，我们发现它们的二进制倒数第4位之后是相同的“111”，对于8来说“1000”，这部分就是余数了，但它们是完全相同的，这样就造成了冲突。</p><p>因此我们在设置除法散列函数是要尽量避免m位2的幂，转而选取离2的幂稍有距离的素数是个不错的选择，对于上面的例子来说，7，13等都是不错的选择。</p><h5 id="乘法散列法">乘法散列法</h5><h5 id="全域散列法">全域散列法</h5><h4 id="冲突处理">冲突处理</h4><p>在对关键字进行散列的时候，不可避免的会发生散列冲突。散列冲突就是说，不同关键字经过散列函数处理后，得到了相同的结果。这就构成了冲突，因为散列表只为该结果提供了一个位置，很明显这些冲突的关键字数据不能都存到这一个地方。（一是，空间不够存不下，二是，就算存的下，之后查找的时候也没法精确找到准确的关键字）</p><p>于是，我们就需要考虑，怎么样把这些冲突的数据存储下来，而且在查找的时候，能通过确定的策略准确的找到它们。</p><p>冲突处理主要有两类方法：开放探测法和链表法。</p><h5 id="开放探测法">开放探测法</h5><p>开放探测法，实质上就是说，在设计散列表的时候，把散列范围再稍微扩大一点。就像是说，有一个柜子，它的抽屉不够放这些东西，那么我们给这个柜子加一些抽屉，加的这些抽屉就是用来放冲突数据的。本质上这种方法，柜子还是柜子，只是加了一些抽屉罢了。</p><p>开放探测法有一些具体的方法，例如：线性探测法、平方探测法、双散列法。</p><h6 id="线性探测">线性探测</h6><p>顾名思义，线性探测，就是在关键字通过散列函数计算并得到散列值遭遇冲突后，通过在散列表上前后移动一定数量i查找是否存在该关键字。</p><blockquote><p>例子：</p></blockquote><h6 id="平方探测">平方探测</h6><p>平方探测指的是，在遭遇冲突后，在散列表上移动i的平方，来查找是否存在。</p><blockquote><p>例子：</p></blockquote><h6 id="双散列法">双散列法</h6><p>双散列法，就是在遭遇冲突后，再次通过一个散列函数来查找。</p><blockquote><p>例子:</p></blockquote><h5 id="链表法">链表法</h5><p>有很多教材也将链表法形象地称作“拉链法”。简而言之，链表法，就是在原来散列表的各个散列值对于位置挂上一条链表，这个链表用来存储散列函数计算为该散列值的冲突数据，由于链表的特性，可以随时动态的添加。<br>学过Java的同学们应该知道一个叫做HashMap的容器，它最底层的结构就是这个样子的。<br>做个形象的比喻，这种方法就是，这个柜子抽屉不够，那我给每个抽屉编个号码，每个号码对应一个箱子，箱子里装，对应抽屉本该装却装不下的东西。</p><blockquote><p>图片：<br>python实现：</p></blockquote><h4 id="散列表的查找效率">散列表的查找效率</h4><h5 id="从存储空间上分析">从存储空间上分析</h5><p>如何来衡量一个散列表的存储效率呢？<br>我们可以引入一个叫做装填因子的指标，装填因子=散列表中的装载的元素个数÷散列表总容量。其实它本质上就是描述，一个散列表的空间利用率。<br>为什么空间利用率可以用来表示散列表的效率呢，那是因为，散列表存储的数据越多，那么可能发生散列冲突的几率就越高，发生冲突后，搜索效率就会降低。</p><blockquote><p>装填因子 例子：<br>图片：</p></blockquote><h5 id="从结果上分析">从结果上分析</h5><h6 id="成功平均查找长度ASLs">成功平均查找长度ASLs</h6><p>简单来说，当我们查找一个关键字时，其查找的长度就是，找到该关键字在散列表中位置的操作步数,即冲突次数+散列次数（通常是1）。<br>而<strong>成功平均查找长度ASLs</strong>就是指，散列表中所有的元素的查找长度的关于整个散列表的平均值。</p><p>有了ASLs，我们就可以明确一个散列表对该组数据来说，查找的效率怎么样，从而对散列表设置、散列函数设置进行调整，来使得对特定数据散列查找效果最佳。</p><blockquote><p>ASLs例子：<br>图片：</p></blockquote><h6 id="不成功平均查找长度ASLu">不成功平均查找长度ASLu</h6><p>上面我们有了ASLs成功平均查找长度，它衡量的是，找到在散列表中关键字，所需要耗费的平均步骤数。<br>那么如果不在散列表中呢？<br><strong>不成功平均查找长度ASLu</strong>指的是每个散列值（散列表位置）对应的查找失败的步数关于整个散列表位置数的平均值。<br>简单的讲，就是对于已经存储了数据的散列表，假设某个位置散列值为1，那么我们设要查找一个不在散列表中的散列后值为1的关键字，所需要的得到该关键字不在散列表中这一结论的步骤数就是不成功查找长度。<br>所以<br>ASLu = 所有位置的不成功查找长度只和 ÷ 该散列表所有散列位置数</p><blockquote><p>ASLu 例子：<br>图片：</p></blockquote><h3 id="二叉搜索树（BST）">二叉搜索树（BST）</h3><h4 id="何为二叉搜索树">何为二叉搜索树</h4><h5 id="二叉搜索树的构造">二叉搜索树的构造</h5><h5 id="二叉搜索树的搜索">二叉搜索树的搜索</h5><h4 id="二叉搜索树的实现">二叉搜索树的实现</h4><h4 id="二叉搜索树的时间复杂度分析">二叉搜索树的时间复杂度分析</h4><h3 id="总结">总结</h3><p>查找是极其重要的计算机算法，它的本质是对已知的关键字进行查找，返回其位置的一种操作。我们本章介绍了常用的几种查找算法，二分查找、散列查找和二叉搜索树查找。每种查找都有它的特点，适用的环境不同， 性能也不尽相同。二分查找适用于有序的顺序表，它的时间复杂度为O(log2 n),比起顺序查找是一种很好的减少运算次数的算法；散列查找是基于散列表的一种查找，由于散列表的特性，使得它兼具查找和数据修改的便利特性，因此也是日常开发中常用的数据结构与算法，它的性能可以用ASL来衡量，最坏的情况下同顺序查找O(n)，最好情形下O(1)；二叉搜索树查找是利用二叉搜索树的一种查找，它是一种动态查找，它的时间复杂度与二叉搜索树的高度呈现正相关，而二叉搜索树高度可以表示为log n,因此它的时间复杂度为O(log n)。</p>]]></content>
      
      
      <categories>
          
          <category> 数据结构与算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二分查找 </tag>
            
            <tag> 散列表 </tag>
            
            <tag> 二叉搜索树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数学之美——傅立叶变换的本质</title>
      <link href="/2020/06/21/shu-xue-zhi-mei-fu-li-xie-bian-huan-de-ben-zhi/"/>
      <url>/2020/06/21/shu-xue-zhi-mei-fu-li-xie-bian-huan-de-ben-zhi/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="/assets/css/APlayer.min.css"><script src="/assets/js/APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1>数学之美——傅立叶变换的本质</h1><h2 id="引言">引言</h2><p>本文从物理学角度切入浅析了傅立叶变换的本质，用通俗的语言来阐释什么是傅立叶变换，并简单说明了一些傅立叶变换的现实应用原理。相信阅读本文后，读者能对傅立叶变换的重要性有更为深刻直观的认识。</p><blockquote><ul><li>世界上的许多事物之间的相互作用都是基于波。</li><li>人可以听到、看到事物本身就很不可思议。</li><li>看见是因为我们的眼睛接受光波，听见是因为我们的耳朵能接受声波，而主要的是我们的大脑能够将这些波进行处理，得到其中的信息。那么我们的大脑究竟如何做到这一点的呢？</li><li>美颜软件是怎么做到磨皮的？音频和图片压缩是怎么做到的？无线通信又是如何做到的？下面的视频中的字母是如何画出来的？</li></ul></blockquote><p><img src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/FourierOfSETH.GIF" alt="100个向量绘制图形" title="100个向量绘制图形"><br>其实这一切的最根本的原理都是——傅立叶变换。</p><hr><h2 id="何为傅立叶变换">何为傅立叶变换</h2><h3 id="波的叠加">波的叠加</h3><p>要理解傅立叶变换首先要知道，<strong>波是具有可叠加的特性的</strong>。我们高中物理中学到过的，我现在依然较为深刻的，<a href="https://baike.baidu.com/item/%E6%B3%A2%E7%9A%84%E5%B9%B2%E6%B6%89/257113?fr=aladdin" target="_blank" rel="noopener">波的干涉（百度百科）</a>，讲的就是同种介质中的波相互影响而最后呈现出一种新的波。波的叠加后，有的地方振幅增强，有的地方振幅减弱，有的不变。例子就是向平静的湖面扔两块石头，所形成的波浪。</p><p>理解了波的可叠加性，我们就知道原来世界上很多事物都是以波的形式存在的，而其实他们就是由一个又一个“简单的”波而叠加形成的 (<a href="https://zh.wikipedia.org/zh/%E6%B3%A2%E7%B2%92%E4%BA%8C%E8%B1%A1%E6%80%A7" target="_blank" rel="noopener">量子力学：波粒二象性(维基百科)</a>)。<em>他最核心区别于经典力学的想法就是：微观粒子时而表现出波动性，时而表现出粒子性。而波动具有的波长和频率意味着在空间和时间上，波动具有延伸性</em>。</p><h3 id="物理学上傅立叶变换的本质——波叠加的“逆向工程”">物理学上傅立叶变换的本质——波叠加的“逆向工程”</h3><p><strong>傅立叶变换：一种线性积分变换，用于信号在<u>时域</u><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>（或空域）和<u>频域</u><sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>之间的变换。</strong><br>简而言之，就是将自然界复杂的信号，拆分成为基本成分的过程。而为了达到此目的，使用了一种叫做“线性积分变换”的数学方法（后面在“傅立叶变换的数学原理”会介绍）。</p><blockquote><p><a href="http://www.jezzamon.com/fourier/zh-cn.html" target="_blank" rel="noopener" title="傅立叶变换交互式入门">点击了解傅立叶变换过程可视化展示</a></p></blockquote><p><strong>时域波信号</strong>由傅立叶变换被分解出来的基本组成单元正弦波，包含了<strong>振幅</strong>、<strong>相位</strong>，以及它们本身具有的<strong>频率</strong>，既是说傅立叶变换后得到的正弦波们具有：<strong>频率</strong>、<strong>相位</strong>、<strong>振幅</strong>这三个信息。（因为我们更多遇到的是在时间维度而不是空间维度的信号，于是本文主要探讨时域信号&lt;其实是我对空间上的变化一无所知&gt;）</p><p>反过来说，要叠加为一个“不规则”（即自然界中的信号）的波形，其实是在时间轴上不同频率正弦波在同一时间振幅叠加而得的，相位也起到了错位的作用。<br>有的人说 傅立叶变换所得的正弦波是三维的，也就是它们在振幅、相位，和频率这三个维度上。</p><p>所说的信号从时域向频域转换，实质上就是把在时域的三个维度（时间、振幅、相位）转变到频域的三个维度（频率、振幅、相位）。各位可以自己画出三维坐标系体会一下。</p><h3 id="离散or连续">离散or连续</h3><div align=center><img style="width:50%;height:45%" src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/%E6%88%AA%E5%B1%8F2020-06-22%20%E4%B8%8A%E5%8D%881.31.43.png "align=center /></div>对于连续的时域信号，分周期性和非周期性信号，它们所对应的频域信号分别是连续的和离散的。<p>有限个不同频率的弦波所做的叠加，构成的波，如果对它进行傅立叶变换，得到的频谱图，频率维度的取值就是离散的。这对应于傅立叶级数。</p><p>而一般情况下，自然界中的信号都是可以有无限个弦波叠加而来的，我们无法把它们穷举出来。而且这些自然界信号都是非周期性的。对应于连续傅立叶变换。</p><div align=center><img src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/%E7%A6%BB%E6%95%A3%E5%92%8C%E8%BF%9E%E7%BB%AD.jpeg " alt="离散和连续频谱图" /><p> <i>请原谅我的字丑。。。</i></p></div><p>这也是为什么在连续傅立叶变换时使用的数学工具需要用到“积分变换”——针对连续问题。</p><hr><h2 id="傅立叶变换的数学原理">傅立叶变换的数学原理</h2><h3 id="线性代数角度看傅立叶变换的本质——线性变换">线性代数角度看傅立叶变换的本质——线性变换</h3><p>前面我们提到，傅立叶变换是将时域信号转换为频域信号，它们可以看成是三维空间。而傅立叶变换可以看成信号（向量）是从时域三维空间线性变换到频域三维空间。</p><p>因此我们可以把傅立叶变换前的三维空间用一组<strong>正交基</strong>（1，sinwt，coswt）来描述。</p><p>试想我们如果用变换前的波形（向量）来点乘一个与在sinwt与coswt面上的向量（这里我们一般用的是<u>sinwt+icoswt</u> <sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> <strong>欧拉公式</strong>），那么与w不相关的部分都会被消掉（垂直向量的点积为0），于是我们就得到分解出来的弦波（分连续和离散两种情况，离散就是弦波相加&lt;傅立叶级数&gt;，连续可看作是无穷区间上的定积分）。</p><h3 id="欧拉公式——复平面与三角函数的桥梁"><a href="https://zh.wikipedia.org/wiki/%E6%AC%A7%E6%8B%89%E5%85%AC%E5%BC%8F" target="_blank" rel="noopener" title="欧拉公式">欧拉公式</a>——复平面与三角函数的桥梁</h3><p><img style="width:50%;height:50%" src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/oula.png "/><img style="width:50%;height:50%" src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/%E6%AC%A7%E6%8B%89%E5%85%AC%E5%BC%8F.png "/></p><p>由于欧拉公式的存在，那么我们很容易想到，把上面的复平面 sinwt+icoswt（正交向量线性组合，可以扩展向量空间维度），替换为<strong>e</strong>的-i𝛚t次方（加负号不影响代表该平面，在复平面上角速度方向变为顺时针）。<br>于是我们就得到了连续傅立叶变换的表达式：</p><img style="width:50%;height:50%" src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/%E8%BF%9E%E7%BB%AD%E5%82%85%E7%AB%8B%E5%8F%B6%E5%8F%98%E6%8D%A2.png" align=center /><img style="width:50%;height:50%" src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/%E5%82%85%E7%AB%8B%E5%8F%B6%E5%8F%98%E6%8D%A2%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%A7%92%E9%80%9F%E5%BA%A6.png" align=center /><!--![连续傅立叶变换][连续傅立叶变换]--><hr><h2 id="傅立叶变换的应用">傅立叶变换的应用</h2><h3 id="1-利用傅立叶变换原理来绘制图形（曲线拟合曲线）">1.利用傅立叶变换原理来绘制图形（曲线拟合曲线）</h3><div align=center><img style="width:40%;height:40%" src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/FourierOfSETH_30v.GIF" /><img style="width:40%;height:40%" src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/FourierOfSETH_50v.GIF"  /><img style="width:40%;height:40%" src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/FourierOfSETH.GIF"/><img style="width:40%;height:40%" src="http://driver.idongxu.com.cn/ImgHost/2020-06-22/FourierOfSETH_1000v.GIF"/></div>动图依次是由30个、50个，100个，1000个傅立叶变换所得弦波拟合我所自定义图形的过程。<p>其中的圆表示的是各个频率正弦波，半径为振幅，向量箭头初始位置由相位决定，圆转一周的速度由频率决定，所有的向量叠加决定了该时间点最后指向的位置。</p><blockquote><p>动图由 <strong>manim</strong>生成，它是一个基于Python的可视化项目，由3Blue1Brown提供。<br><a href="https://github.com/3b1b/manim" target="_blank" rel="noopener">manim_Github</a></p></blockquote><p><strong>从曲线拟合的角度来看，相较于泰勒用直线拟合曲线的做法，傅立叶是用曲线来拟合曲线。</strong></p><h3 id="2-人脑就是一个高级傅立叶运算器">2.人脑就是一个高级傅立叶运算器</h3><p>人的大脑就像是一台能够进行傅立叶变换的机器，它能分清楚不同波段的声音，不同波段的光线。这也是名侦探柯南剧场版颤栗的乐谱中“绝对音感”的依据。</p><h3 id="3-照片磨皮、音频压缩等原理">3.照片磨皮、音频压缩等原理</h3><p>而美颜和图片、音频压缩是因为，低频决定框架，高频确定细节（就像我动图展示的那样，叠加越多高频正弦波，越接近“完美”），我们可以利用这一点，适当减少高频，来使得原来的媒体在总体不变的情况下，降低大小或是减少细节。</p><h2 id="结语">结语</h2><p>总之，(连续)傅立叶变换是一种线性积分变换，用于信号在时域（或空域）到频域之间的变换。它的数学原理就是线性变换，然后如果频率是连续的（时域连续非周期），那么就需要进行积分。而傅立叶级数是把类似的波表示成为简单弦波的组合，对应的是时域连续周期性信号。利用这些原理我们可以解析信号，压缩拟合等；反过来我们可以用符合特征的弦波叠加为所需的信号。</p><p>由于能力时间有限，不足或错漏之处还请海涵，并恳请不吝赐教。</p><p><a href="https://charlesliuyx.github.io/2018/02/18/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E8%AE%A9%E4%BD%A0%E6%B0%B8%E8%BF%9C%E5%BF%98%E4%B8%8D%E4%BA%86%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%E8%A7%A3%E6%9E%90/" target="_blank" rel="noopener">友链，作为补充</a></p><h2 id="注解">注解</h2><!--[连续傅立叶变换]: http://i1.fuimg.com/721720/e1437990f22475f0.png "连续傅立叶变换表达式"--><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>描述数学函数或物理信号对时间的关系。例如一个信号的时域波形可以表达信号随着时间的变化。 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>指在对函数或信号进行分析时，分析其和频率有关部份，而不是和时间有关的部份，和时域一词相对。 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>复数实际上是一种用一个数就能标识二维坐标的标记，通过这种写法我们可以表示一个平面。此处这个平面是振幅和相位的二维平面。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li></ol></section>]]></content>
      
      
      <categories>
          
          <category> 数学 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 微积分 </tag>
            
            <tag> 傅立叶 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
